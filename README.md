# DeepSeek-Benchmarking-locally-1.3B-and-7B-models
Benchmarking DeepSeek 1.3B and 7B models with FP16 and 8bit quantizations locally using HuggingFace and lm-eval-harness with mobile RTX 4090

# DeepSeek Benchmarking

Due to GitHub file size limits, the full project archive (1.8 TB) is available here:

➡️ [Download ZIP from Google Drive](https://drive.google.com/drive/folders/1yqX7MidSt2ZWt5pU6W4t16uU1UG-KTB3?usp=sharing)

To use it, unzip and follow the instructions in `README.txt` inside.
